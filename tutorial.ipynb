{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018c9687",
   "metadata": {},
   "source": [
    "# Data Validation Tutorial\n",
    "Welcome to the data validation tutorial using tensorflow data validation! In this tutorial we will be using tensorflow data validation (or tfdv) to write data tests. The tutorial is divided into the following segments:\n",
    "\n",
    "1. TFDV Exploration: we will start by exploring the fundamentals of tfdv.\n",
    "2. Data validation: next we will write some *tests* for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa7eb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.12.0\n",
      "TFDV version: 1.13.0\n"
     ]
    }
   ],
   "source": [
    "# put your import statements here\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "print('TF version:', tf.__version__)\n",
    "print('TFDV version:', tfdv.version.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175269f8",
   "metadata": {},
   "source": [
    "## Part 1: TFDV Exploration\n",
    "In this section we will explore the basics of tfdv. Follow the instructions below.\n",
    "\n",
    "### 1.1 Load the data\n",
    "Use `pandas` to load the csv file as a dataframe.\n",
    "\n",
    "+ *Hint*: did you check the [10 minutes with pandas guide]? Did you read the *Getting data in/out* section?\n",
    "+ *Hint*: did you import pandas as `pd`?\n",
    "\n",
    "[10 minutes with pandas guide]: https://pandas.pydata.org/docs/user_guide/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11322fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "df = pd.read_csv(\"./data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6cbad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b014f68",
   "metadata": {},
   "source": [
    "### 1.2 Create train-test split\n",
    "Use sklearn to create a 75-25 train-test split (in favour of train).\n",
    "\n",
    "**NOTE**: Use 42 as the `random_state` so that we have reproducible splits.\n",
    "\n",
    "+ *Hint*: did you check the api documentation for [sklearn.model_selection]?\n",
    "+ *Hint*: did you import the necessary function?\n",
    "\n",
    "[sklearn.model_selection]: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c8f6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "X, y = sklearn.model_selection.train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bba6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
      "287       8913         B       12.890         13.12           81.89   \n",
      "512     915691         M       13.400         20.52           88.64   \n",
      "402     904689         B       12.960         18.29           84.18   \n",
      "446    9110732         M       17.750         28.03          117.30   \n",
      "210  881046502         M       20.580         22.14          134.70   \n",
      "..         ...       ...          ...           ...             ...   \n",
      "71      859711         B        8.888         14.64           58.79   \n",
      "106     863031         B       11.640         18.33           75.17   \n",
      "270    8910721         B       14.290         16.82           90.30   \n",
      "435     908489         M       13.980         19.62           91.12   \n",
      "102     862965         B       12.180         20.52           77.22   \n",
      "\n",
      "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
      "287      515.9          0.06955           0.03729         0.02260   \n",
      "512      556.7          0.11060           0.14690         0.14450   \n",
      "402      525.2          0.07351           0.07899         0.04057   \n",
      "446      981.6          0.09997           0.13140         0.16980   \n",
      "210     1290.0          0.09090           0.13480         0.16400   \n",
      "..         ...              ...               ...             ...   \n",
      "71       244.0          0.09783           0.15310         0.08606   \n",
      "106      412.5          0.11420           0.10170         0.07070   \n",
      "270      632.6          0.06429           0.02675         0.00725   \n",
      "435      599.5          0.10600           0.11330         0.11260   \n",
      "102      458.7          0.08013           0.04038         0.02383   \n",
      "\n",
      "     concave points_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "287              0.01171  ...          15.54            87.40       577.0   \n",
      "512              0.08172  ...          29.66           113.30       844.4   \n",
      "402              0.01883  ...          24.61            96.31       621.9   \n",
      "446              0.08293  ...          38.54           145.40      1437.0   \n",
      "210              0.09561  ...          27.84           158.30      1656.0   \n",
      "..                   ...  ...            ...              ...         ...   \n",
      "71               0.02872  ...          15.67            62.56       284.4   \n",
      "106              0.03485  ...          29.26            85.51       521.7   \n",
      "270              0.00625  ...          20.65            94.44       684.6   \n",
      "435              0.06463  ...          30.80           113.90       869.3   \n",
      "102              0.01770  ...          32.84            84.58       547.8   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "287           0.09616            0.11470          0.11860   \n",
      "512           0.15740            0.38560          0.51060   \n",
      "402           0.09329            0.23180          0.16040   \n",
      "446           0.14010            0.37620          0.63990   \n",
      "210           0.11780            0.29200          0.38610   \n",
      "..                ...                ...              ...   \n",
      "71            0.12070            0.24360          0.14340   \n",
      "106           0.16880            0.26600          0.28730   \n",
      "270           0.08567            0.05036          0.03866   \n",
      "435           0.16130            0.35680          0.40690   \n",
      "102           0.11230            0.08862          0.11450   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
      "287               0.05366          0.2309                  0.06915   \n",
      "512               0.20510          0.3585                  0.11090   \n",
      "402               0.06608          0.3207                  0.07247   \n",
      "446               0.19700          0.2972                  0.09075   \n",
      "210               0.19200          0.2909                  0.05865   \n",
      "..                    ...             ...                      ...   \n",
      "71                0.04786          0.2254                  0.10840   \n",
      "106               0.12180          0.2806                  0.09097   \n",
      "270               0.03333          0.2458                  0.06120   \n",
      "435               0.18270          0.3179                  0.10550   \n",
      "102               0.07431          0.2694                  0.06878   \n",
      "\n",
      "     Unnamed: 32  \n",
      "287          NaN  \n",
      "512          NaN  \n",
      "402          NaN  \n",
      "446          NaN  \n",
      "210          NaN  \n",
      "..           ...  \n",
      "71           NaN  \n",
      "106          NaN  \n",
      "270          NaN  \n",
      "435          NaN  \n",
      "102          NaN  \n",
      "\n",
      "[426 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad994def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "204     87930         B        12.47         18.60           81.09      481.9   \n",
      "70     859575         M        18.94         21.31          123.60     1130.0   \n",
      "131      8670         M        15.46         19.48          101.70      748.9   \n",
      "431    907915         B        12.40         17.68           81.47      467.8   \n",
      "540    921385         B        11.54         14.44           74.65      402.9   \n",
      "..        ...       ...          ...           ...             ...        ...   \n",
      "89     861598         B        14.64         15.24           95.77      651.9   \n",
      "199    877500         M        14.45         20.22           94.49      642.7   \n",
      "411    905520         B        11.04         16.83           70.92      373.2   \n",
      "18     849014         M        19.81         22.15          130.00     1260.0   \n",
      "390  90317302         B        10.26         12.22           65.75      321.6   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "204          0.09965           0.10580         0.08005              0.03821   \n",
      "70           0.09009           0.10290         0.10800              0.07951   \n",
      "131          0.10920           0.12230         0.14660              0.08087   \n",
      "431          0.10540           0.13160         0.07741              0.02799   \n",
      "540          0.09984           0.11200         0.06737              0.02594   \n",
      "..               ...               ...             ...                  ...   \n",
      "89           0.11320           0.13390         0.09966              0.07064   \n",
      "199          0.09872           0.12060         0.11800              0.05980   \n",
      "411          0.10770           0.07804         0.03046              0.02480   \n",
      "18           0.09831           0.10270         0.14790              0.09498   \n",
      "390          0.09996           0.07542         0.01923              0.01968   \n",
      "\n",
      "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "204  ...          24.64            96.05       677.9            0.1426   \n",
      "70   ...          26.58           165.90      1866.0            0.1193   \n",
      "131  ...          26.00           124.90      1156.0            0.1546   \n",
      "431  ...          22.91            89.61       515.8            0.1450   \n",
      "540  ...          19.68            78.78       457.8            0.1345   \n",
      "..   ...            ...              ...         ...               ...   \n",
      "89   ...          18.24           109.40       803.6            0.1277   \n",
      "199  ...          30.12           117.90      1044.0            0.1552   \n",
      "411  ...          26.44            79.93       471.4            0.1369   \n",
      "18   ...          30.88           186.80      2398.0            0.1512   \n",
      "390  ...          15.65            73.23       394.5            0.1343   \n",
      "\n",
      "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "204             0.2378          0.26710               0.10150          0.3014   \n",
      "70              0.2336          0.26870               0.17890          0.2551   \n",
      "131             0.2394          0.37910               0.15140          0.2837   \n",
      "431             0.2629          0.24030               0.07370          0.2556   \n",
      "540             0.2118          0.17970               0.06918          0.2329   \n",
      "..                 ...              ...                   ...             ...   \n",
      "89              0.3089          0.26040               0.13970          0.3151   \n",
      "199             0.4056          0.49670               0.18380          0.4753   \n",
      "411             0.1482          0.10670               0.07431          0.2998   \n",
      "18              0.3150          0.53720               0.23880          0.2768   \n",
      "390             0.1650          0.08615               0.06696          0.2937   \n",
      "\n",
      "     fractal_dimension_worst  Unnamed: 32  \n",
      "204                  0.08750          NaN  \n",
      "70                   0.06589          NaN  \n",
      "131                  0.08019          NaN  \n",
      "431                  0.09359          NaN  \n",
      "540                  0.08134          NaN  \n",
      "..                       ...          ...  \n",
      "89                   0.08473          NaN  \n",
      "199                  0.10130          NaN  \n",
      "411                  0.07881          NaN  \n",
      "18                   0.07615          NaN  \n",
      "390                  0.07722          NaN  \n",
      "\n",
      "[143 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6bf8d",
   "metadata": {},
   "source": [
    "### 1.3 Use tfdv to compute statistics for the training set\n",
    "Generate descriptive statistics for the training set using tfdv.\n",
    "\n",
    "+ *Hint*: you already know what to do...[read the docs]! Look for the appropriate `generate_statistics_from...` method.\n",
    "+ *Hint*: did you import tensorflow data validation as `tfdv`?\n",
    "\n",
    "[read the docs]: https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481b45e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5774bd",
   "metadata": {},
   "source": [
    "### 1.4 Visualise training stats & make observations\n",
    "Lets visualise the statistics for our training set & see how it looks like. In particular, make the following observations:\n",
    "\n",
    "1. Look at the distribution of the features\n",
    "1. Look at the range of values for numerical features\n",
    "1. Look at the values for categorical features\n",
    "1. Do we have any missing values?\n",
    "1. Explore the UI: change the feature sort order, change the chart type, etc.\n",
    "\n",
    "+ *Hint*: there is only one method in tfdv that can do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de074483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b32f4",
   "metadata": {},
   "source": [
    "***Reflect on the following questions:***\n",
    "\n",
    "1. Is the visualisation provided by tfdv useful?\n",
    "1. Can tfdv be used during data exploration & understanding?\n",
    "1. Do we have any features that do not follow a *normal distribution*? Will this affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5700fd4",
   "metadata": {},
   "source": [
    "### 1.5 Visualise testing stats & make observations\n",
    "Lets now also make sure that our test set is *similar* to our training set. Generate the statistics for the test set & visulise it alongside the train set.\n",
    "\n",
    "+ *Hint*: did you read the api documentation for the method you used to visualise statistics carefully? Can you visualise statistics of two datasets at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61c965",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd0817",
   "metadata": {},
   "source": [
    "***Reflect on the following questions:***\n",
    "\n",
    "1. Are the training & testing splits similar?\n",
    "1. Can tfdv be used during data exploration & understanding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bad491",
   "metadata": {},
   "source": [
    "## Part 2: Data Validation\n",
    "In this section we will write tests for our data. TFDV does this by first creating a *schema* for our data which specifies what we expect our data to look like. In SE terms, the schema is the *test oracle* which we can use to check if our tests are passing or failing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866be1db",
   "metadata": {},
   "source": [
    "### 2.1 Create a schema\n",
    "Generate a schema from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a327a8",
   "metadata": {},
   "source": [
    "### 2.2 Inspect the schema\n",
    "\"Pretty print\" the schema that was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bb97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751abb2",
   "metadata": {},
   "source": [
    "***Reflect on the following:***\n",
    "\n",
    "+ Does the schema make sense?\n",
    "+ Does it need to be modified?\n",
    "+ What about this `Unnamed: 32` column?\n",
    "+ Do we really need the `id` column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227e5c9",
   "metadata": {},
   "source": [
    "#### 2.2.1 Cleanup the schema\n",
    "Drop the columns we don't need & recreate the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed82368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c38c5a",
   "metadata": {},
   "source": [
    "### 2.3 Inspect anomalies in test set\n",
    "Now lets check if our test set meets the expectations that we define in our schema. First, use tfdv to find the *anomalies* (a.k.a bugs) in our test set and then \"pretty print\" them.\n",
    "\n",
    "+ *Hint*: I will give you the answer for this one! You need to use the `validate_statistics` method followed by the appropriate `display...` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07045260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b0bdd",
   "metadata": {},
   "source": [
    "### 2.4 Make the bugs go away!\n",
    "Can you fix the issue here? We did this for the training set already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
